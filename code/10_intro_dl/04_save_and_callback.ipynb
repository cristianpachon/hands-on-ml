{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(3, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(3, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 3s 238us/sample - loss: 1015.5781 - val_loss: 1.3516\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.3383 - val_loss: 1.3513\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.3379 - val_loss: 1.3512\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 1.3383 - val_loss: 1.3512\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 1.3381 - val_loss: 1.3512\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 1.3380 - val_loss: 1.3522\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.3375 - val_loss: 1.3525\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 1.3385 - val_loss: 1.3512\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.3379 - val_loss: 1.3517\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 1.3383 - val_loss: 1.3512\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 1.3383 - val_loss: 1.3512\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 1.3382 - val_loss: 1.3512\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 1.3382 - val_loss: 1.3512\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.3380 - val_loss: 1.3523\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 1.3383 - val_loss: 1.3513\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 1.3382 - val_loss: 1.3516\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.3379 - val_loss: 1.3520\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 1.3381 - val_loss: 1.3520\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.3383 - val_loss: 1.3512\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.3380 - val_loss: 1.3517\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model is just as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit() method accepts a callbacks argument that lets you specify a list of ojects that Keras will will call at the start and end of the training, at the start and end of each epoch, and even before and after processing each batch. For example, the ModelCheckpoint callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 83us/sample - loss: 1.3372 - val_loss: 1.3519\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 1.3383 - val_loss: 1.3512\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 1.3380 - val_loss: 1.3512\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.3380 - val_loss: 1.3519\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 1.3382 - val_loss: 1.3518\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 1.3381 - val_loss: 1.3524\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 1.3382 - val_loss: 1.3515\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 1.3380 - val_loss: 1.3518\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 1.3379 - val_loss: 1.3527\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.3380 - val_loss: 1.3517\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "hystory = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
